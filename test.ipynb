{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_preprocess import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import talib as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data\\ETHBTC-5m-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df):\n",
    "    if (df['Trend'] == 0) or (df['Trend'] == 1 and df['Previous_Trend'] == 1) or (df['Trend'] == -1 and df['Previous_Trend'] == -1):\n",
    "        return 'Hold'\n",
    "    elif (df['Trend'] == 1) and (df['Previous_Trend'] == 0 or -1):\n",
    "        return 'Buy'\n",
    "    elif (df['Trend'] == -1) and (df['Previous_Trend'] == 0 or 1):\n",
    "        return 'Sell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Next_Close</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Previous_Trend</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-14 05:55:00</th>\n",
       "      <td>0.085506</td>\n",
       "      <td>0.085782</td>\n",
       "      <td>0.085341</td>\n",
       "      <td>0.085399</td>\n",
       "      <td>13.840</td>\n",
       "      <td>0.088591</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-14 06:00:00</th>\n",
       "      <td>0.085399</td>\n",
       "      <td>0.085460</td>\n",
       "      <td>0.085398</td>\n",
       "      <td>0.085460</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.088591</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-14 06:05:00</th>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.086204</td>\n",
       "      <td>0.085402</td>\n",
       "      <td>0.086186</td>\n",
       "      <td>101.722</td>\n",
       "      <td>0.088591</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-14 06:10:00</th>\n",
       "      <td>0.086274</td>\n",
       "      <td>0.087001</td>\n",
       "      <td>0.086274</td>\n",
       "      <td>0.086973</td>\n",
       "      <td>59.807</td>\n",
       "      <td>0.088591</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-14 06:15:00</th>\n",
       "      <td>0.087097</td>\n",
       "      <td>0.087097</td>\n",
       "      <td>0.086898</td>\n",
       "      <td>0.086899</td>\n",
       "      <td>28.800</td>\n",
       "      <td>0.086252</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Open      High       Low     Close   Volume  \\\n",
       "Timestamp                                                              \n",
       "2017-07-14 05:55:00  0.085506  0.085782  0.085341  0.085399   13.840   \n",
       "2017-07-14 06:00:00  0.085399  0.085460  0.085398  0.085460    0.606   \n",
       "2017-07-14 06:05:00  0.085470  0.086204  0.085402  0.086186  101.722   \n",
       "2017-07-14 06:10:00  0.086274  0.087001  0.086274  0.086973   59.807   \n",
       "2017-07-14 06:15:00  0.087097  0.087097  0.086898  0.086899   28.800   \n",
       "\n",
       "                     Next_Close  Trend  Previous_Trend Label  \n",
       "Timestamp                                                     \n",
       "2017-07-14 05:55:00    0.088591      1               0   Buy  \n",
       "2017-07-14 06:00:00    0.088591      1               1  Hold  \n",
       "2017-07-14 06:05:00    0.088591      1               1  Hold  \n",
       "2017-07-14 06:10:00    0.088591      1               1  Hold  \n",
       "2017-07-14 06:15:00    0.086252     -1               1  Sell  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataLabeling\n",
    "data = df.set_index('Timestamp').iloc[:, :5]\n",
    "data['STD'] = data.Close.rolling(24).std()\n",
    "data['Next_Close'] = data.Close.shift(-24)\n",
    "data = data.dropna()\n",
    "data['Trend'] = np.where(data.Next_Close >= data.Close*(1+0.55*data.STD), 1,\n",
    "                         np.where(data.Next_Close <= data.Close*(1-0.55*data.STD), -1, 0))\n",
    "data['Previous_Trend'] = data.Trend.shift(fill_value=0)\n",
    "data = data.drop(['STD'], axis=1)\n",
    "# data['Next_Trend'] = data.Next_Trend.astype(int)\n",
    "data = data.assign(Label=data.apply(func, axis=1))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = DataLabeling(df, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dddru\\Documents\\GitHub\\Is-Technical-Indicator-Really-a-Thing-for-Deep-Learning\\utils\\data_preprocess.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  np.where(data.Next_Close <= data.Close*(1-self.__alpha*data.STD), 2, 0))\n",
      "c:\\Users\\dddru\\Documents\\GitHub\\Is-Technical-Indicator-Really-a-Thing-for-Deep-Learning\\utils\\data_preprocess.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Previous_Trend'] = data.Trend.shift(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = train_val_test_split(raw_data.labelled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = DataPreprocess(train_df, val_df, test_df, window_size=24, label_size=1, label_columns=['Label'], shift=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, 24, 5), (None, 1, 1)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential, Model, Input\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrongModel:\n",
    "    def __init__(self, window_size, features):\n",
    "        self.window_size = window_size\n",
    "        self.features = features\n",
    "        \n",
    "    def __CNN_blocks(self, id, filters, kernel_size, pool_size, pool_strides):\n",
    "        block = tf.keras.Sequential([\n",
    "            tf.keras.layers.Convolution2D(filters=filters, kernel_size=(1, kernel_size), strides=1, padding='same'),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(1, pool_size), strides=(1, pool_strides), padding='valid')\n",
    "        ], name=f'feature_extractor_{id}')\n",
    "    \n",
    "        return block\n",
    "    \n",
    "    def train(self, train_data, epochs, val_data):\n",
    "        self.model.fit(train_data,\n",
    "                       epochs=epochs,\n",
    "                       steps_per_epoch=len(train_data),\n",
    "                       validation_data=val_data,\n",
    "                       validation_steps=int(0.15*len(val_data)),\n",
    "                       use_multiprocessing=True,\n",
    "                       callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "                       monitor='val_loss', verbose=1, patience=15, restore_best_weights=True),\n",
    "                                  tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5)])\n",
    "    \n",
    "    @property\n",
    "    def model(self):\n",
    "        input = tf.keras.Input(shape=(self.window_size, self.features), name='input_layer')\n",
    "        x = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=3), name='add_dim')(input)\n",
    "        x = tf.keras.layers.Permute((2, 1, 3), name='feature_time_transpose')(x)\n",
    "        x = self.__CNN_blocks(id=1, filters=32, kernel_size=4, pool_size=4, pool_strides=4)(x)\n",
    "        x = self.__CNN_blocks(id=2, filters=64, kernel_size=3, pool_size=3, pool_strides=3)(x)\n",
    "        x = self.__CNN_blocks(id=3, filters=128, kernel_size=2, pool_size=2, pool_strides=2)(x)\n",
    "        x = tf.keras.layers.Lambda(lambda x: tf.squeeze(x, axis=2), name='reduce_dim')(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dense(500, activation='relu')(x)\n",
    "        output = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "        model = tf.keras.Model(input, output, name='strong_baseline')\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = StrongModel(24, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2481/2481 [==============================] - 28s 9ms/step - loss: 0.4437 - accuracy: 0.8876 - val_loss: 0.4111 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "2481/2481 [==============================] - 24s 10ms/step - loss: 0.4324 - accuracy: 0.8880 - val_loss: 0.4042 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 0.4337 - accuracy: 0.8880 - val_loss: 0.4047 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 0.4302 - accuracy: 0.8881 - val_loss: 0.4007 - val_accuracy: 0.8975 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "2481/2481 [==============================] - 23s 9ms/step - loss: 0.4295 - accuracy: 0.8881 - val_loss: 0.4020 - val_accuracy: 0.8975 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 0.4279 - accuracy: 0.8881 - val_loss: 0.4035 - val_accuracy: 0.8975 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 0.4278 - accuracy: 0.8882 - val_loss: 0.4046 - val_accuracy: 0.8975 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 0.4280 - accuracy: 0.8882 - val_loss: 0.4025 - val_accuracy: 0.8975 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 0.4278 - accuracy: 0.8882 - val_loss: 0.4025 - val_accuracy: 0.8975 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 0.4278 - accuracy: 0.8882 - val_loss: 0.4024 - val_accuracy: 0.8975 - lr: 8.0000e-04\n",
      "Epoch 11/500\n",
      "2481/2481 [==============================] - 23s 9ms/step - loss: 0.4278 - accuracy: 0.8882 - val_loss: 0.4024 - val_accuracy: 0.8975 - lr: 8.0000e-04\n",
      "Epoch 12/500\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 0.4278 - accuracy: 0.8882 - val_loss: 0.4024 - val_accuracy: 0.8975 - lr: 8.0000e-04\n",
      "Epoch 13/500\n",
      "2481/2481 [==============================] - 21s 9ms/step - loss: 0.4278 - accuracy: 0.8882 - val_loss: 0.4024 - val_accuracy: 0.8975 - lr: 8.0000e-04\n",
      "Epoch 14/500\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 0.4278 - accuracy: 0.8882 - val_loss: 0.4024 - val_accuracy: 0.8975 - lr: 8.0000e-04\n",
      "Epoch 15/500\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 0.4278 - accuracy: 0.8882 - val_loss: 0.4024 - val_accuracy: 0.8975 - lr: 6.4000e-04\n",
      "Epoch 16/500\n",
      "2481/2481 [==============================] - 23s 9ms/step - loss: 0.4278 - accuracy: 0.8882 - val_loss: 0.4024 - val_accuracy: 0.8975 - lr: 6.4000e-04\n",
      "Epoch 17/500\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 0.4278 - accuracy: 0.8882 - val_loss: 0.4024 - val_accuracy: 0.8975 - lr: 6.4000e-04\n",
      "Epoch 18/500\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 0.4297 - accuracy: 0.8881 - val_loss: 0.4024 - val_accuracy: 0.8975 - lr: 6.4000e-04\n",
      "Epoch 19/500\n",
      "2481/2481 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.8882Restoring model weights from the end of the best epoch: 4.\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 0.4278 - accuracy: 0.8882 - val_loss: 0.4024 - val_accuracy: 0.8975 - lr: 6.4000e-04\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "test.train(Data.train, 500, Data.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, layers, Model, Sequential\n",
    "\n",
    "# Create CNN blocks for feature extraction\n",
    "\n",
    "def CNN_blocks(id, filters, kernel_size, pool_size, pool_strides):\n",
    "    block = Sequential([\n",
    "        layers.Convolution2D(filters=filters, kernel_size=(1, kernel_size), strides=1, padding='same'),\n",
    "        layers.MaxPool2D(pool_size=(1, pool_size), strides=(1, pool_strides), padding='valid')\n",
    "    ], name=f'feature_extractor_{id}')\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 6, 128)\n",
      "(None, 768)\n"
     ]
    }
   ],
   "source": [
    "# Create model using Model API\n",
    "input = Input(shape=(24, 6), name='input_layer')\n",
    "x = layers.Lambda(lambda x: tf.expand_dims(x, axis=3), name='add_dim')(input)\n",
    "x = layers.Permute((2, 1, 3), name='feature_time_transpose')(x)\n",
    "x = CNN_blocks(id=1, filters=32, kernel_size=4, pool_size=4, pool_strides=4)(x)\n",
    "x = CNN_blocks(id=2, filters=64, kernel_size=3, pool_size=3, pool_strides=3)(x)\n",
    "x = CNN_blocks(id=3, filters=128, kernel_size=2, pool_size=2, pool_strides=2)(x)\n",
    "x = layers.Lambda(lambda x: tf.squeeze(x, axis=2), name='reduce_dim')(x)\n",
    "print(x.shape)\n",
    "x = layers.Flatten()(x)\n",
    "print(x.shape)\n",
    "x = layers.Dense(1000, activation='relu')(x)\n",
    "x = layers.Dense(500, activation='relu')(x)\n",
    "output = layers.Dense(3, activation='softmax')(x)\n",
    "model = Model(input, output, name='strong_baseline')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac3da779536756720bc930bbdcbe3b303a716c4190960bb8b007750e7b6b7c5d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
