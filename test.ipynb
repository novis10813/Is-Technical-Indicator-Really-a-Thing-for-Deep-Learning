{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils.data_preprocess import * # data_split, DataLabeling, train_val_test_split\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data\\ETHBTC-5m-data.csv')\n",
    "raw_data = DataLabeling(df, WINDOW_SIZE)\n",
    "train_df, val_df, test_df = train_val_test_split(raw_data.labelled_data)\n",
    "Data = DataPreprocess(train_df, val_df, test_df, WINDOW_SIZE, label_size=1, label_columns=['Trend'], shift=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CDT_1D_model(24, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11867/11867 [==============================] - 270s 23ms/step - loss: 0.7784 - accuracy: 0.5704 - val_loss: 99.0767 - val_accuracy: 0.0059\n",
      "Epoch 2/20\n",
      "11867/11867 [==============================] - 311s 26ms/step - loss: 0.7726 - accuracy: 0.5829 - val_loss: 285.6733 - val_accuracy: 0.4320\n",
      "Epoch 3/20\n",
      "11867/11867 [==============================] - 265s 22ms/step - loss: 0.7602 - accuracy: 0.5908 - val_loss: 82.7184 - val_accuracy: 0.5621\n",
      "Epoch 4/20\n",
      "11867/11867 [==============================] - 308s 26ms/step - loss: 0.7469 - accuracy: 0.5952 - val_loss: 46.7466 - val_accuracy: 0.5621\n",
      "Epoch 5/20\n",
      "11867/11867 [==============================] - 261s 22ms/step - loss: 0.7427 - accuracy: 0.5964 - val_loss: 28.7002 - val_accuracy: 0.0059\n",
      "Epoch 6/20\n",
      "11867/11867 [==============================] - 249s 21ms/step - loss: 0.7392 - accuracy: 0.5975 - val_loss: 3.1382 - val_accuracy: 0.5621\n",
      "Epoch 7/20\n",
      "11867/11867 [==============================] - 280s 24ms/step - loss: 0.7390 - accuracy: 0.5969 - val_loss: 16.3147 - val_accuracy: 0.5621\n",
      "Epoch 8/20\n",
      "11867/11867 [==============================] - 252s 21ms/step - loss: 0.7380 - accuracy: 0.5973 - val_loss: 3.4098 - val_accuracy: 0.5621\n",
      "Epoch 9/20\n",
      "11867/11867 [==============================] - 275s 23ms/step - loss: 0.7376 - accuracy: 0.5967 - val_loss: 9.8737 - val_accuracy: 0.5621\n",
      "Epoch 10/20\n",
      "11867/11867 [==============================] - 281s 24ms/step - loss: 0.7371 - accuracy: 0.5979 - val_loss: 15.2235 - val_accuracy: 0.5621\n",
      "Epoch 11/20\n",
      "11867/11867 [==============================] - 260s 22ms/step - loss: 0.7365 - accuracy: 0.5976 - val_loss: 19.0614 - val_accuracy: 0.0059\n",
      "Epoch 12/20\n",
      "11867/11867 [==============================] - 270s 23ms/step - loss: 0.7364 - accuracy: 0.5975 - val_loss: 1.7223 - val_accuracy: 0.5325\n",
      "Epoch 13/20\n",
      "11867/11867 [==============================] - 335s 28ms/step - loss: 0.7362 - accuracy: 0.5964 - val_loss: 2.7855 - val_accuracy: 0.4320\n",
      "Epoch 14/20\n",
      "11867/11867 [==============================] - 310s 26ms/step - loss: 0.7358 - accuracy: 0.5979 - val_loss: 2.3465 - val_accuracy: 0.5621\n",
      "Epoch 15/20\n",
      "11867/11867 [==============================] - 247s 21ms/step - loss: 0.7354 - accuracy: 0.5987 - val_loss: 4.3093 - val_accuracy: 0.5621\n",
      "Epoch 16/20\n",
      "11867/11867 [==============================] - 256s 22ms/step - loss: 0.7356 - accuracy: 0.5975 - val_loss: 11.5789 - val_accuracy: 0.5621\n",
      "Epoch 17/20\n",
      "11867/11867 [==============================] - 251s 21ms/step - loss: 0.7351 - accuracy: 0.5978 - val_loss: 3.0066 - val_accuracy: 0.5621\n",
      "Epoch 18/20\n",
      "11867/11867 [==============================] - 254s 21ms/step - loss: 0.7354 - accuracy: 0.5986 - val_loss: 18.3460 - val_accuracy: 0.5621\n",
      "Epoch 19/20\n",
      "11867/11867 [==============================] - 263s 22ms/step - loss: 0.7351 - accuracy: 0.5982 - val_loss: 6.0690 - val_accuracy: 0.5621\n",
      "Epoch 20/20\n",
      "11867/11867 [==============================] - 274s 23ms/step - loss: 0.7349 - accuracy: 0.5977 - val_loss: 6.7381 - val_accuracy: 0.5621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c6e19adf08>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.fit(Data.train,\n",
    "               epochs=20,\n",
    "               validation_data=Data.val,\n",
    "               steps_per_epoch=len(Data.train),\n",
    "               validation_steps=int(0.15*len(Data.val)),\n",
    "               callbacks=[create_model_checkpoint(model_name=test_model.name, save_path='without_TIs'),\n",
    "                          tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),\n",
    "                          tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, min_lr=0.00001, factor=0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 2.3767 - accuracy: 0.7808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3766791820526123, 0.7808219194412231]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.evaluate(Data.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(169,), dtype=int64, numpy=\n",
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(test_model.predict(Data.val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    104\n",
       "0     87\n",
       "1      1\n",
       "Name: Trend, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.Trend.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac3da779536756720bc930bbdcbe3b303a716c4190960bb8b007750e7b6b7c5d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
